# Malaria Detection using CNN - Estudo Comparativo

ImplementaÃ§Ã£o de um **estudo comparativo multi-experimento** para classificaÃ§Ã£o de imagens de detecÃ§Ã£o de malÃ¡ria baseado no artigo **"Efficient deep learning-based approach for malaria detection using red blood cell smears"** (Scientific Reports, 2024).

## ğŸ“‹ DescriÃ§Ã£o

Este projeto implementa e compara **3 configuraÃ§Ãµes diferentes** de Redes Neurais Convolucionais (CNN) para classificar cÃ©lulas sanguÃ­neas em parasitadas (malÃ¡ria positivo) ou nÃ£o infectadas, utilizando o dataset pÃºblico "Malaria Cell Images Dataset" do Kaggle.

### CaracterÃ­sticas do Dataset

- **Total**: 27.558 imagens (balanceado 50/50)
- **Classes**: Parasitized (13.779) e Uninfected (13.779)
- **Tamanho das imagens**: 50Ã—50Ã—3 pixels
- **Fonte**: [Kaggle - Malaria Cell Images Dataset](https://www.kaggle.com/datasets/iarunava/cell-images-for-detecting-malaria)

### Resultados Obtidos

- **Baseline (Paper)**: 93.34% de acurÃ¡cia
- **Alta Capacidade**: 94.32% de acurÃ¡cia
- **Augmentation Agressivo**: 94.61% de acurÃ¡cia (melhor resultado)
- **AcurÃ¡cia reportada no paper**: 97.00%

## ğŸ—ï¸ Arquitetura dos Modelos

O projeto implementa **3 experimentos diferentes** para comparaÃ§Ã£o:

### Experimento 1: Baseline (Paper) ğŸ¯

ReplicaÃ§Ã£o exata da configuraÃ§Ã£o do artigo de referÃªncia:

- **3 blocos convolucionais**: Conv2D (32, 64, 128 filtros) + ReLU
- MaxPooling2D (2Ã—2) + BatchNormalization + Dropout (0.25)
- **Camada densa**: 128 neurÃ´nios + ReLU + Dropout (0.5)
- **SaÃ­da**: 1 neurÃ´nio com Sigmoid
- **Total de parÃ¢metros**: ~684K

### Experimento 2: Alta Capacidade ğŸš€

Rede com maior capacidade para testar se mais parÃ¢metros melhoram o desempenho:

- **3 blocos convolucionais**: Conv2D (64, 128, 256 filtros) - **dobro da capacidade**
- MaxPooling2D (2Ã—2) + BatchNormalization + Dropout (0.3)
- **Camada densa**: 256 neurÃ´nios + ReLU + Dropout (0.5)
- **SaÃ­da**: 1 neurÃ´nio com Sigmoid

### Experimento 3: Augmentation Agressivo + RegularizaÃ§Ã£o ğŸ²

Data augmentation intenso e maior regularizaÃ§Ã£o para melhorar generalizaÃ§Ã£o:

- **3 blocos convolucionais**: Conv2D (32, 64, 128 filtros) - igual ao baseline
- MaxPooling2D (2Ã—2) + BatchNormalization + Dropout (0.4) - **maior regularizaÃ§Ã£o**
- **Camada densa**: 128 neurÃ´nios + ReLU + Dropout (0.6)
- **SaÃ­da**: 1 neurÃ´nio com Sigmoid

## ğŸš€ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio

```bash
git clone <repository-url>
cd malaria-cnn-classification
```

### 2. Crie e ative um ambiente virtual (Python 3.8+)

```bash
# Criar ambiente virtual
python3 -m venv venv

# Ativar o ambiente virtual
# No macOS/Linux:
source venv/bin/activate

# No Windows:
venv\Scripts\activate
```

### 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 4. Configure a API do Kaggle

Para baixar o dataset automaticamente, vocÃª precisa configurar suas credenciais do Kaggle:

1. Crie uma conta no [Kaggle](https://www.kaggle.com/)
2. VÃ¡ em "Account" â†’ "API" â†’ "Create New API Token"
3. Isso baixarÃ¡ um arquivo `kaggle.json`
4. Coloque o arquivo no local apropriado:
   - **Linux/Mac**: `~/.kaggle/kaggle.json`
   - **Windows**: `C:\Users\<username>\.kaggle\kaggle.json`
5. Configure as permissÃµes (Linux/Mac):
   ```bash
   chmod 600 ~/.kaggle/kaggle.json
   ```

## ğŸ“Š Uso

### Executar o notebook completo

```bash
jupyter notebook malaria_detection.ipynb
```

O notebook contÃ©m todas as etapas do estudo comparativo:

1. Download e organizaÃ§Ã£o do dataset
2. AnÃ¡lise exploratÃ³ria dos dados
3. ConfiguraÃ§Ã£o dos 3 experimentos
4. ConstruÃ§Ã£o das arquiteturas CNN
5. Treinamento dos 3 modelos
6. AvaliaÃ§Ã£o e comparaÃ§Ã£o dos resultados
7. GeraÃ§Ã£o de grÃ¡ficos e tabelas comparativas

### Estrutura do Projeto

```
malaria-cnn-classification/
â”œâ”€â”€ malaria_detection.ipynb    # Notebook principal com estudo comparativo
â”œâ”€â”€ requirements.txt            # DependÃªncias Python
â”œâ”€â”€ README.md                   # DocumentaÃ§Ã£o
â”œâ”€â”€ data/                       # Dataset (criado automaticamente)
â”‚   â””â”€â”€ cell_images/
â”‚       â”œâ”€â”€ Parasitized/
â”‚       â””â”€â”€ Uninfected/
â”œâ”€â”€ models/                     # Modelos treinados e mÃ©tricas
â”‚   â”œâ”€â”€ baseline_paper_*         # Resultados do experimento 1
â”‚   â”œâ”€â”€ exp2_high_capacity_*     # Resultados do experimento 2
â”‚   â”œâ”€â”€ exp3_augmentation_*      # Resultados do experimento 3
â”‚   â””â”€â”€ comparative_results.csv  # Tabela comparativa
â””â”€â”€ figures/                    # GrÃ¡ficos e visualizaÃ§Ãµes
    â”œâ”€â”€ *_training_curves.png    # Curvas de treinamento
    â”œâ”€â”€ *_confusion_matrix.png   # Matrizes de confusÃ£o
    â””â”€â”€ *_comparison.png         # GrÃ¡ficos comparativos
```

## ğŸ”¬ Metodologia

### PrÃ©-processamento (Comum a todos os experimentos)

- **Redimensionamento**: 50Ã—50Ã—3 pixels
- **NormalizaÃ§Ã£o**: [0, 1] (rescale=1./255)
- **Split**: 80% treino (22.048 imagens) / 20% validaÃ§Ã£o (5.510 imagens)
- **Data augmentation**: Varia por experimento (ver detalhes abaixo)

### ConfiguraÃ§Ãµes de Treinamento por Experimento

#### Experimento 1: Baseline (Paper)

- **Otimizador**: Adam (lr=0.0001)
- **Loss**: Binary Crossentropy
- **Batch size**: 64
- **Epochs**: 15
- **Data augmentation**: Apenas flips horizontal e vertical
- **Dropout**: 0.25 (conv) / 0.5 (dense)

#### Experimento 2: Alta Capacidade

- **Otimizador**: Adam (lr=0.0001)
- **Loss**: Binary Crossentropy
- **Batch size**: 64
- **Epochs**: 20
- **Data augmentation**: Apenas flips horizontal e vertical
- **Dropout**: 0.3 (conv) / 0.5 (dense)

#### Experimento 3: Augmentation Agressivo

- **Otimizador**: Adam (lr=0.0005)
- **Loss**: Binary Crossentropy
- **Batch size**: 32
- **Epochs**: 20
- **Data augmentation**: Flips + rotaÃ§Ã£o (15Â°) + zoom (0.1) + shifts (0.1)
- **Dropout**: 0.4 (conv) / 0.6 (dense)

### Callbacks (Comuns a todos)

- **Early Stopping**: Monitora `val_loss` com patience=3
- **Model Checkpoint**: Salva melhor modelo baseado em `val_accuracy`
- **ReduceLROnPlateau**: Reduz learning rate quando `val_loss` para de melhorar

### MÃ©tricas Avaliadas

- AcurÃ¡cia (Accuracy)
- PrecisÃ£o (Precision)
- Recall (Sensibilidade)
- F1-Score
- AUC (Area Under Curve)
- Matriz de ConfusÃ£o

## ğŸ“ˆ Resultados

### Resultados por Experimento

| Experimento                | AcurÃ¡cia   | Precision | Recall | F1-Score   |
| -------------------------- | ---------- | --------- | ------ | ---------- |
| **Baseline (Paper)**       | 93.34%     | 0.9070    | 0.9659 | 0.9355     |
| **Alta Capacidade**        | 94.32%     | 0.9348    | 0.9528 | 0.9437     |
| **Augmentation Agressivo** | **94.61%** | 0.9235    | 0.9728 | **0.9475** |

### AnÃ¡lise Comparativa

- **Melhor resultado**: Experimento 3 (Augmentation Agressivo) com 94.61% de acurÃ¡cia
- **ComparaÃ§Ã£o com paper**: Todos os experimentos ficaram abaixo da acurÃ¡cia reportada (97%), mas com resultados consistentes e prÃ³ximos
- **Insights**:
  - Aumentar a capacidade da rede (Exp 2) melhorou ligeiramente os resultados
  - Data augmentation agressivo + regularizaÃ§Ã£o (Exp 3) obteve o melhor desempenho geral

### Artefatos Gerados

O notebook gera automaticamente:

- **Modelos treinados**: `.h5` files para cada experimento
- **HistÃ³rico de treinamento**: JSON com mÃ©tricas por Ã©poca
- **RelatÃ³rios de classificaÃ§Ã£o**: Text files com mÃ©tricas detalhadas
- **GrÃ¡ficos de treinamento**: Curvas de loss, accuracy, precision e recall
- **Matrizes de confusÃ£o**: VisualizaÃ§Ãµes para cada experimento
- **GrÃ¡ficos comparativos**: ComparaÃ§Ã£o de acurÃ¡cia, F1-score e mÃ©tricas entre experimentos
- **Tabela comparativa**: CSV com todos os resultados

## ğŸ”— ReferÃªncias

- **Paper**: "Efficient deep learning-based approach for malaria detection using red blood cell smears" - Scientific Reports, 2024
- **Dataset**: [Malaria Cell Images Dataset - Kaggle](https://www.kaggle.com/datasets/iarunava/cell-images-for-detecting-malaria)

## ğŸ“ LicenÃ§a

Este projeto Ã© para fins educacionais e de pesquisa.

## ğŸ¯ Objetivos do Estudo

Este projeto foi desenvolvido para:

1. **Validar a implementaÃ§Ã£o**: Replicar o baseline do paper para garantir correÃ§Ã£o
2. **Explorar variaÃ§Ãµes**: Testar diferentes estratÃ©gias (capacidade vs augmentation)
3. **Comparar abordagens**: Identificar qual configuraÃ§Ã£o funciona melhor
4. **Gerar insights**: Entender trade-offs entre complexidade e desempenho

## ğŸ“ Notas TÃ©cnicas

- **Framework**: TensorFlow 2.20.0 / Keras 3.12.0
- **Reprodutibilidade**: Seeds fixos (42) para garantir resultados reproduzÃ­veis
- **GPU**: Suporta GPU, mas funciona tambÃ©m em CPU
- **Tempo de treinamento**: ~15-20 minutos por experimento em CPU moderno

## ğŸ‘¥ Autor

Implementado como estudo comparativo baseado nas especificaÃ§Ãµes do paper cientÃ­fico mencionado.
